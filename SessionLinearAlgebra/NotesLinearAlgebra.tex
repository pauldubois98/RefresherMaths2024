\documentclass[]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{stmaryrd}

\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Primes}{\mathbb{P}}
\newcommand{\st}{\text{ s.t. }}
\newcommand{\txtand}{\text{ and }}
\newcommand{\txtor}{\text{ or }}
\newcommand{\lxor}{\veebar}

%opening
\title{Notes on Calculus}
\author{Paul Dubois}
\date{}

\begin{document}
	
	\maketitle
	
	\begin{abstract}
		
	\end{abstract}
	
	
	\section{Linear Independence Property}
	
	Given a set of vectors $\{\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n\}$ in a vector space $V$, the set is said to be \textbf{linearly independent} if the only solution to the equation
	$$
	c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + \dots + c_n\mathbf{v}_n = \mathbf{0}
	$$
	is 
	$$
	c_1 = c_2 = \dots = c_n = 0.
	$$\\
	In other words, none of the vectors in the set can be written as a linear combination of the others.
	
	\noindent \textbf{Example:}
	Consider the vectors
	$\mathbf{v}_1 = \begin{pmatrix} 3 \\ 2 \\ 4 \\ -1 \\ 2 \end{pmatrix}$,
	$\mathbf{v}_2 = \begin{pmatrix} -2 \\ 5 \\ 0 \\ 1 \\ 1 \end{pmatrix}$
	and
	$\mathbf{v}_3 = \begin{pmatrix} 1 \\ 0 \\ 5 \\ 3 \\ -4 \end{pmatrix}$
	in $\mathbb{R}^5$.
	These vectors are linearly independent because the only solution to
	$$
	c_1v_1 + c_2v_2 + c_3v_3 = \mathbf{0}
	$$
	is $c_1 = c_2 = c_3 = 0$.
	
	\section{Spanning Property}
	
	A set of vectors $\{\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n\}$ in a vector space $V$ is said to \textbf{span} $V$ if every vector in $V$ can be expressed as a linear combination of these vectors.
	Mathematically, the set spans $V$ if for every vector $\mathbf{v} \in V$, there exist scalars $c_1, c_2, \dots, c_n$ such that
	$$
	\mathbf{v} = c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + \dots + c_n\mathbf{v}_n.
	$$
	
	\noindent \textbf{Example:}
	In $\mathbb{R}^2$, the vectors
	$\mathbf{v}_1 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}$,
	$\mathbf{v}_2 = \begin{pmatrix} -1 \\ 2 \end{pmatrix}$
	and
	$\mathbf{v}_3 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}$
	span $\mathbb{R}^2$ because any vector
	$\mathbf{v} = \begin{pmatrix} x \\ y \end{pmatrix}$
	can be written as
	$$
	\mathbf{v} = x\mathbf{v}_1 + (y-x)\mathbf{v}_2 + (y-x)\mathbf{v}_2.
	$$
	
	\section{Basis}
	
	A set of vectors $\{\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_n\}$ in a vector space $V$ is called a \textbf{basis} for $V$ if:
	\begin{itemize}
		\item The set is linearly independent.
		\item The set spans the vector space $V$.
	\end{itemize}
	
	The number of vectors in a basis is called the \textbf{dimension} of the vector space.
	
	\noindent \textbf{Example:}
	The vectors $\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$ and $\mathbf{v}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}$ form a basis for $\mathbb{R}^2$.
	The dimension of $\mathbb{R}^2$ is 2.
	
	\section{(Reduced) Row Echelon Form}
	
	A matrix is in \textbf{row echelon form} if it satisfies the following conditions:
	\begin{enumerate}
		\item All non-zero rows are above any rows of all zeros.
		\item The leading entry of each non-zero row after the first occurs to the right of the leading entry of the previous row.
		\item The leading entry in any non-zero row is 1 (this condition is for the \textbf{reduced} row echelon form).
		\item The leading 1 is the only non-zero entry in its column (for \textbf{reduced} row echelon form).
	\end{enumerate}
	
	\textbf{Example:} The matrix
	$$
	\begin{pmatrix}
		1 & 2 & 3 \\
		0 & 1 & 4 \\
		0 & 0 & 1
	\end{pmatrix}
	$$
	is in row echelon form.
	
	\section{Inverting a Matrix}
	
	The \textbf{inverse} of a square matrix $A$ is denoted by $A^{-1}$ and is defined as the matrix that satisfies
	$$
	AA^{-1} = A^{-1}A = I,
	$$
	where $I$ is the identity matrix.
	
	\textbf{Steps to find the inverse of a matrix:}
	\begin{enumerate}
		\item Form the augmented matrix $[A | I]$.
		\item Use row operations to convert $A$ into the identity matrix.
		\item The matrix that results from the identity matrix on the left side is $A^{-1}$ on the right side.
	\end{enumerate}
	
	\textbf{Example:} For the matrix
	$$
	A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix},
	$$
	the augmented matrix is
	$$
	[A | I] = \begin{pmatrix}
		1 & 2 & \mid & 1 & 0\\
		3 & 4 & \mid & 0 & 1
	\end{pmatrix}
	$$
	after reducing to row echelon form:
	$$
	[I | A^{-1}] = \begin{pmatrix}
		1 & 0 & \mid & -2 & 1\\
		0 & 1 & \mid & 1.5 & -0.5
	\end{pmatrix}
	$$
	hence, the inverse is
	$$
	A^{-1} = \begin{pmatrix}
		-2 & 1\\
		1.5 & -0.5
	\end{pmatrix}
	$$
	
	\section{Determinant}
	
	The \textbf{determinant} of a square matrix $A$, denoted by $\text{det}(A)$, is a scalar value that can be computed from the elements of the matrix. The determinant has important properties and applications, including:
	\begin{itemize}
		\item A matrix is invertible if and only if its determinant is non-zero.
		\item The determinant of a product of matrices is the product of their determinants: $\text{det}(AB) = \text{det}(A)\text{det}(B)$.
	\end{itemize}
	
	For a $2 \times 2$ matrix $A = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$, the determinant is calculated as:
	$$
	\text{det}(A) = ad - bc.
	$$
	
	For a $3 \times 3$ matrix $A = \begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix} $, the determinant is calculated as:
	$$
	\text{det}(A) =
	  a \begin{vmatrix} e & f \\ h & i \end{vmatrix}
	- b \begin{vmatrix} d & f \\ g & i \end{vmatrix}
	+ c \begin{vmatrix} d & e \\ g & h \end{vmatrix}.
	$$
	
	Expanding the $2 \times 2$ determinants (minors):
	$$
	\text{det}(A) = a(ei - fh) - b(di - fg) + c(dh - eg).
	$$
	
	For higher dimension matrices, ask a computer (it's outside the scope of this course).
	
	\noindent \textbf{Example:} For the matrix
	$$
	B = \begin{pmatrix} 1 & 2 \\ 2 & 4 \end{pmatrix},
	$$
	$\det{B} = 0$, hence, the matrix is not invertible (you can try to invert it, you will encounter a problem).
	
	While for the matrix
	$$
	A = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix},
	$$
	$\det{A} = -2 \neq 0$, hence, the matrix is invertible (and we found the inverse in the previous section).
		
	\section{Eigenvalues}
	
	\subsection{Definition}
	
	Let \( A \) be an \( n \times n \) matrix. A scalar \( \lambda \) is called an \textbf{eigenvalue} of \( A \) if there exists a non-zero vector \( \mathbf{v} \in \mathbb{R}^n \) (or \( \mathbb{C}^n \)) such that
	\[
	A \mathbf{v} = \lambda \mathbf{v}.
	\]
	The vector \( \mathbf{v} \) is referred to as the corresponding \textbf{eigenvector} of \( A \) associated with \( \lambda \).
	
	\subsection{Finding Eigenvalues}
	
	To find the eigenvalues of a matrix \( A \), we solve the characteristic equation:
	\[
	\det(A - \lambda I) = 0,
	\]
	where \( I \) is the identity matrix of the same size as \( A \), and \( \det(\cdot) \) denotes the determinant. The solutions \( \lambda \) are the eigenvalues of \( A \).
	
	\subsection{Example}
	
	Consider the matrix
	\[
	A = \begin{pmatrix}
		4 & 1 \\
		2 & 3
	\end{pmatrix}.
	\]
	The characteristic equation is given by:
	\[
	\det(A - \lambda I) = \det\left(\begin{pmatrix}
		4 & 1 \\
		2 & 3
	\end{pmatrix} - \lambda \begin{pmatrix}
		1 & 0 \\
		0 & 1
	\end{pmatrix}\right) = \det\left(\begin{pmatrix}
		4-\lambda & 1 \\
		2 & 3-\lambda
	\end{pmatrix}\right) = (4-\lambda)(3-\lambda) - 2 = \lambda^2 - 7\lambda + 10 = 0.
	\]
	The eigenvalues are the roots of this quadratic equation, \( \lambda_1 = 5 \) and \( \lambda_2 = 2 \).
	
	\section{Eigenvectors}
	
	\subsection{Definition}
	
	Given an eigenvalue \( \lambda \) of a matrix \( A \), the corresponding \textbf{eigenvector} \( \mathbf{v} \) is any non-zero vector that satisfies the equation:
	\[
	A \mathbf{v} = \lambda \mathbf{v}.
	\]
	To find the eigenvectors associated with \( \lambda \), we solve the system:
	\[
	(A - \lambda I)\mathbf{v} = 0.
	\]
	This is a system of linear equations.
	
	\subsection{Example}
	
	For the matrix \( A \) from the previous example and \( \lambda_1 = 5 \), we solve:
	\[
	(A - 5I)\mathbf{v} = \begin{pmatrix}
		-1 & 1 \\
		2 & -2
	\end{pmatrix} \mathbf{v} = \mathbf{0}.
	\]
	The solution to this system is \( \mathbf{v}_1 = \begin{pmatrix} 1 \\ 1 \end{pmatrix} \). Similarly, for \( \lambda_2 = 2 \), we solve:
	\[
	(A - 2I)\mathbf{v} = \begin{pmatrix}
		2 & 1 \\
		2 & 1
	\end{pmatrix} \mathbf{v} = \mathbf{0},
	\]
	which gives \( \mathbf{v}_2 = \begin{pmatrix} -1 \\ 2 \end{pmatrix} \).
	
	\section{Diagonalization}
	
	\subsection{Definition}
	
	A square matrix \( A \) is said to be \textbf{diagonalizable} if there exists an invertible matrix \( P \) and a diagonal matrix \( D \) such that:
	\[
	A = PDP^{-1},
	\]
	where the diagonal elements of \( D \) are the eigenvalues of \( A \), and the columns of \( P \) are the corresponding eigenvectors.
	
	\subsection{Procedure for Diagonalization}
	
	\begin{enumerate}
		\item Find the eigenvalues \( \lambda_1, \lambda_2, \ldots, \lambda_n \) of \( A \).
		\item For each eigenvalue \( \lambda_i \), find the corresponding eigenvector \( \mathbf{v}_i \).
		\item Form the matrix \( P \) using the eigenvectors as columns: \( P = \begin{pmatrix} \mathbf{v}_1 & \mathbf{v}_2 & \ldots & \mathbf{v}_n \end{pmatrix} \).
		\item The matrix \( D \) is a diagonal matrix with eigenvalues on the diagonal: \( D = \text{diag}(\lambda_1, \lambda_2, \ldots, \lambda_n) \).
		\item Verify that \( A = PDP^{-1} \).
	\end{enumerate}
	
	\subsection{Example}
	
	Consider the matrix \( A = \begin{pmatrix} 4 & 1 \\ 2 & 3 \end{pmatrix} \). From our earlier work, the eigenvalues are \( \lambda_1 = 5 \) and \( \lambda_2 = 2 \), with corresponding eigenvectors \( \mathbf{v}_1 = \begin{pmatrix} 1 \\ 1 \end{pmatrix} \) and \( \mathbf{v}_2 = \begin{pmatrix} -1 \\ 2 \end{pmatrix} \).
	
	Thus, we can form:
	\[
	P = \begin{pmatrix} 1 & -1 \\ 1 & 2 \end{pmatrix}, \quad D = \begin{pmatrix} 5 & 0 \\ 0 & 2 \end{pmatrix}.
	\]
	Finally, verify that:
	\[
	P^{-1} = \frac{1}{3} \begin{pmatrix} 2 & 1 \\ -1 & 1 \end{pmatrix}, \quad A = PDP^{-1} = \begin{pmatrix} 4 & 1 \\ 2 & 3 \end{pmatrix}.
	\]
	
	% linear independence property
	% spanning property
	% basis (def)
	% row echelon form
	% inverting a matrix
	% determinent
	% eigen values
	% eigen vectors
	% diagonalization
	
\end{document}
